---
---

@string{aps = {American Physical Society,}}



@INPROCEEDINGS{Atikuzzaman,
  author={Atikuzzaman, Md. and Asaduzzaman, Md. and Islam, Md. Zahidul},
  booktitle={2019 International Conference on Sustainable Technologies for Industry 4.0 (STI)}, 
  title={Vehicle Number Plate Detection and Categorization Using CNNs}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={Real-Time Vehicle Number Plate Recognition (ANPR) has been a recurrent subject of research study as a result of many real-world implementations. Yet, numerous of todayâs works are still not Full-bodied and consistent in real-world circumstances and rely on various constraints. Our proposed method to detect and recognize license plates in real-time that is particularly designed to work on videos captured by a camera. It is a distinct approach that is composed of three main phases like plate detection, class letter segmentation, and recognition. These phases are completed by adopting a HAAR Feature-based Classifier to detect license plate, class letter extractor with a proposed method, and Convolution Neural Network for recognizing class letters. Our given method achieved captivating results in our collected dataset. Our dataset composed of 5500 license plates and it achieved a successful recognition rate of 91.38% with approximately 30 frames/second. We evaluate our License Plate Detection system performance with 390 test images and we get 96.92% accuracy and Class Letter Segmentation has achieved 94.61% with the same size of data. We achieved an overall successful recognition rate of 90.90% with real-time performance.},
  keywords={},
  doi={10.1109/STI47673.2019.9068049},
  link={https://ieeexplore.ieee.org/abstract/document/9068049},
  ISSN={},
  month={Dec},
 selected={true}}

@INPROCEEDINGS{9350508,
  author={Atikuzzaman, Md. and Rahman, Tarafder Razibur and Wazed, Eashita and Hossain, Md. Parvez and Islam, Md. Zahidul},
  booktitle={2020 2nd International Conference on Sustainable Technologies for Industry 4.0 (STI)}, 
  title={Human Activity Recognition System from Different Poses with CNN}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={In the principle of Human Activity Recognition, a variety of real-life implementations are available using different types of sensors such as fitness monitoring, day-life monitoring, health monitoring, etc. Especially for the elders, sensor-based applications are not feasible due to many reasons such as carrying a mobile phone or gadgets. In this paper, we focused on CCTV videos and camera images to detect human poses using HAAR Feature-based Classifier and recognize the activities of the human using the Convolutional Neural Network (CNN) Classifier. Our Human Activity Recognition System was trained using our own collected dataset which is composed of 5648 images. The approach accomplished an efficacious detection accuracy of 99.86% and recognition accuracy of 99.82% with approximately 22 frames/second after 20 epochs.},
  keywords={},
  doi={10.1109/STI50764.2020.9350508},
  link={https://ieeexplore.ieee.org/abstract/document/9350508},
  ISSN={},
  month={Dec},}
  
  @INPROCEEDINGS{9333508,
  author={Hossain, Md. Parvez and Atikuzzaman, Md. and Rahim, Md. Mushfikur and Hossain, Md. Tuzammel and Mousome, Monira Sultana and Rahaman, Muhammad Aminur},
  booktitle={2020 2nd International Conference on Advanced Information and Communication Technology (ICAICT)}, 
  title={Human Robot Interaction System for Behavioral Improvement of Autistic Children}, 
  year={2020},
  volume={},
  number={},
  pages={117-122},
  abstract={An estimated one-third of people with autism are nonverbal. Many Research has been done in this field and confirms that people with autism experience a lack of communication skills, anxiety, dealing with change, bullying, etc. To assist autistic children and to improve their behavior, we have developed an artificial intelligence robot that can react to their movement via an ultrasonic sensor and can talk to them via voice commands. Using this robot, children with ASD can develop both their behavior and communication skill. The robot works in two methods. The first one is the ultrasonic sensor, implemented with an AI algorithm that can detect a person within seventy centimeters. This ultrasonic sensor sends the data to the controller and the controller receives the signal and sends an activation signal to the robot. Finally, the robot moves his head to the direction of the person is located or to the moving direction. The second method is voice commands. The robot can perform each physical action it is given via voice commands like a salute, handshaking, body movement, and answering questions achieving 97.75% average accuracy with the response time of 328.75ms. This accuracy is achieved by testing the system for 10 iterations. As autistic children hesitate to communicate freely with normal people, this human-robot interaction will improve their behavior and communication skills as well. This humanoid robot will improve the quality of living of the autistic or disabled people. This humanoid robot can be used in any public sector like school, colleges, an autism center, and industry.},
  keywords={},
  doi={10.1109/ICAICT51780.2020.9333508},
  link={https://ieeexplore.ieee.org/abstract/document/9333508},
  ISSN={},
  month={Nov},}
  
  @INPROCEEDINGS{9732584,
  author={Rahman, Md. Mijanur and Afrin, Mst. Sadia and Atikuzzaman, Md. and Rahaman, Muhammad Aminur},
  booktitle={2021 3rd International Conference on Sustainable Technologies for Industry 4.0 (STI)}, 
  title={Real-Time Anomaly Detection and Classification from Surveillance Cameras Using Deep Neural Network}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={With increasing security threats, anomaly detection and classification are highly recommended work nowadays. Anomaly detection and classification from surveillance videos are more complex tasks due to the prevalence of anomalous activity. There are still some exceptional problems that require advanced approaches. Deep learning has recently made it possible to detect and classify anomalies in a critical way. In this paper, we have proposed a fine-tuned ResNet-50 model to learn anomalous patterns by exploiting 14 types of anomalous images. In our approach, we have first augmented the image data before passing it to the model. Instead of a fully connected layer, we have added an average pooling layer, dropout layer, flatten, dense layer, and dense layer followed by an activation function (softmax). We also introduce a new dataset that consists of 10483 real-world anomalous images, with 14 realistic anomalies, including abuse, fire, road accident, robbery, suicide attempt, etc. Increasing the classification performance, such baselines demonstrate that it is incredibly tough for our dataset and opens up more opportunities for future work<sup>1</sup>. In terms of accuracy, our proposed model can acquire 100% accuracy for anomaly detection, and for anomaly classification, on average, it acquires 79.69% accuracy with a computational cost of 61.45 milliseconds per frame.},
  keywords={},
  doi={10.1109/STI53101.2021.9732584},
  link={https://ieeexplore.ieee.org/abstract/document/9732584},
  ISSN={},
  month={Dec},}
  
  @article{pervej2021real,
  title={Real-time computer vision-based bangla vehicle license plate recognition using contour analysis and prediction algorithm},
  author={Pervej, Masud and Das, Sabuj and Hossain, Md Parvez and Atikuzzaman, Md. and Mahin, Md and Rahaman, Muhammad Aminur},
  journal={International Journal of Image and Graphics},
  volume={21},
  number={04},
  pages={2150042},
  abstract={Computer vision-based recognition of Bangle vehicle license plates (LPs) is an arduous task in dirty and muddy situations. This paper proposes an efficient method for real-time computer vision-based recognition of Bangla vehicle LPs using contour analysis and prediction algorithms. The method initially applies gray scaling the input RGB images, histogram equalization to improve the grayscale image quality, edge detection using Sobel edge detector, and adaptive thresholding to convert it to a binary image. The system localizes the vehicle LP based on the maximum rectangular contour area and converts it into a predefined size. Noise removal technique using morphological dilation and erosion operation is used, followed by Gaussian filtering on binary image to improve the image quality further. The system clusters the two-lined LP into seven clusters. The sub-clustering is applied on specific clusters and makes 68 individual sub-clusters. The system extracts vector contour (VC) from each 68 individual classes. After VC extraction, the system normalizes it into a q predefined length. The system applies inter co-relation function (ICF) to categorize each sub-cluster to its previously defined individual class. For that, it calculates the maximum similarity between test and previously trained VCs. The system applies the dependency prediction algorithm in parallel to predict the whole string (district name) in the cluster-1 based on previously categorized class or classes (starting character or characters of the district part). (Metro) or (null) from cluster-2, “-” (hyphen) from cluster-3 and 6 are predicted automatically as their positions are fixed. The system is trained using 68 classes in which each class contains 100 samples generated by the augmentation technique. The system is tested using another set of 68 classes with a total of 68×100=6800 images acquiring the recognition accuracy of 96.62% with the mean computational cost of 8.363ms/f. The system is also tested using 500 vehicle whole Bangla LPs achieving the mean whole LP recognition accuracy of 95.41% with a mean computational cost of 35.803ms/f.},
  year={2021},
  doi={https://doi.org/10.1142/S021946782150042X},
  link={https://www.worldscientific.com/doi/abs/10.1142/S021946782150042X},
  publisher={World Scientific},
 selected={true}
}
@article{atikuzzaman2021comparative,
author={Atikuzzaman, Md. and Hossain, Md Parvez and Islam, Md Zahidul and Kabir, Syed Ahsanul},
title={A Comparative Analysis of Convolutional Neural Networks for Trash Classification},
journal={GUB Journal of Science and Engineering (GUBJSE)},
abstract={In the era of the twenty-first century, automation is the biggest field of research. Although several works have been done successfully, there is still so much to do. Increasing trash could be the biggest threat to a better human life in the future. To automate the task, machines need to understand the type of trash to be recycled or separate similar trash for recycling. For this process, the perfect classification of trash plays a vital role in making a better life and a cleaner world. There are so many popular convolutional neural network (CNN) models for image classification. In this work, we examine and analyze the outcomes of several Residual Network (ResNet) and Visual Geometry Group (VGG) CNN models on a trash dataset. Our main investigation is the accuracy evaluation for different VGG and ResNet models where the training dataset, test dataset, number of epochs, and batch size are the same for all the models. Finally, we compare VGG and ResNet models with each other. We have got the peak accuracy for ResNet152 among all ResNet models and the peak accuracy on VGG16 among all VGG models. And we have got the maximum accuracy on ResNet152 among all the ResNet and VGG models which is about 94%.},
volume={8},
number={01},
pages={17--23},
year={2021}
}

@inproceedings{atikuzzaman2024efficient,
  title={Efficient and Effective INR: A Dive into Levels-of-Experts (LoE) and Sine Activation},
  author={Atikuzzaman, Md. and Bae, Sung-Ho},
  booktitle={2024 International Conference on Information Networking (ICOIN)},
  pages={496--499},
  year={2024},
  organization={IEEE},
 selected={true}
}

@article{atikuzzaman2024beyond,
  title={Beyond Random Noise: Investigating Alternative Initialization Strategies for Dataset Condensation},
  author={Atikuzzaman, Md. and Bae, Sung-Ho},
  journal={한국방송미디어공학회 학술발표대회 논문집},
  pages={1005--1008},
  year={2024}
}
@article{atikuzzaman2024accelerating,
  title={Accelerating and Diversifying Diffusion Sampling with Grayscale Diffusion and GAN-Based Colorization},
  author={Atikuzzaman, Md. and Bae, Sung-Ho},
  journal={한국방송미디어공학회 학술발표대회 논문집},
  pages={1178--1182},
  year={2024}
}

@inproceedings{hossain2024mirror,
  title={Mirror Text Classification from Image Using Machine Learning Techniques},
  author={Hossain, Md Parvez and Atikuzzaman, Md. and Rahman, Mahmuda and Refat, Md Abu Rumman and Hussain, Md Gulzar},
  booktitle={International Conference on Multi-Strategy Learning Environment},
  pages={177--188},
  year={2024},
  organization={Springer}
}
